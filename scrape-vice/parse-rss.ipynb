{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfbab0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyquery import PyQuery as pq\n",
    "from tqdm import tqdm\n",
    "\n",
    "import csv\n",
    "import datetime\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bf83609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 31148/31148 [15:44<00:00, 32.99it/s]\n"
     ]
    }
   ],
   "source": [
    "rssdir = \"rss/\"\n",
    "masterlist = []\n",
    "for rssfile in tqdm(glob(rssdir + \"*\")):\n",
    "    if \".aria2\" not in rssfile:   # Skip stuff still downloading\n",
    "        indexfile = rssfile.replace(rssdir, \"\").replace(rssdir.replace('/', '\\\\'), '')\n",
    "        with open(rssfile, \"rb\") as infile:\n",
    "            html = infile.read()\n",
    "            for item in pq(html)(\"item\"):\n",
    "                line = {}\n",
    "                line[\"rssindex\"] = indexfile\n",
    "                authors = []\n",
    "                for au in pq(item)(\"dc\\:creator\"):\n",
    "                    authors.append(pq(au).text().strip())\n",
    "                line[\"authors\"] = \"|\".join(authors)\n",
    "                line['title'] = pq(pq(item)(\"title\")).text().strip()\n",
    "                line['introtext'] = pq(pq(pq(item)(\"description\"))[0]).html()\n",
    "                line['good-date'] = \"\"\n",
    "                line['original-date'] = pq(pq(item).html().replace(\"pubDate\", \"pubdate\"))(\"pubdate\").text()\n",
    "                # Tue, 25 Aug 2020 11:38:02 GMT\n",
    "                line[\"good-date\"] = datetime.datetime.strptime(line['original-date'], \"%a, %d %b %Y %H:%M:%S GMT\")\n",
    "                line[\"good-date\"] = datetime.datetime.strftime(line['good-date'], \"%Y-%m-%d %H%M%S\")    \n",
    "                line[\"maybe-archive\"] = \"https://web.archive.org/web/*/\"\n",
    "                line[\"maybe-archive\"] += pq(pq(item)(\"link\")).text().replace(\"https://cms.\", \"\").replace(\"https://www.\", \"\")    \n",
    "                line['original-link'] = pq(pq(item)(\"link\")).text()\n",
    "                categories = []\n",
    "                for cat in pq(item)(\"category\"):\n",
    "                    categories.append(pq(cat).text())\n",
    "                line['categories'] = '|'.join(categories)\n",
    "                masterlist.append(line)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1202989",
   "metadata": {},
   "source": [
    "# No, this doesn't work, and I don't care that much\n",
    "\n",
    "# Moving target with ongoing publication mean some entries may have been duplicated\n",
    "print(f\"{len(masterlist):,} raw entries parsed\")\n",
    "masterlist = list(set(masterlist))    # Knock out duplicates\n",
    "print(f\"{len(masterlist):,} de-duplicated entries parsed\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f95fd02",
   "metadata": {},
   "source": [
    "# Complete file is too big for Google Sheets.\n",
    "with open(\"vice-rss-index.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(list(masterlist[0].keys()))\n",
    "    for row in sorted(masterlist, key=lambda d: d['good-date'], reverse=True):\n",
    "        writer.writerow(list(row.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93f4a802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we need to split this damn thing up into a several files -- maybe 2020s, late 2010s, early 2010s, late 2000s.\n",
    "sortedlist = sorted(masterlist, key=lambda d: d['good-date'], reverse=True)\n",
    "yearholder = {}\n",
    "for row in sortedlist:\n",
    "    year = row['good-date'][:4]\n",
    "    if year not in yearholder:\n",
    "        yearholder[year] = []\n",
    "    yearholder[year].append(row)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71ce78a6",
   "metadata": {},
   "source": [
    "yearsetup = {\n",
    "    \"2020s-early\": [\"2024\", \"2023\", \"2022\", \"2021\", \"2020\"],\n",
    "    \"2010s-late\": [\"2019\", \"2018\", \"2017\", \"2016\", \"2015\"],\n",
    "    \"2010s-early\": [\"2014\", \"2013\", \"2012\", \"2011\", \"2010\"],\n",
    "    \"2000s-late\": [\"2009\", \"2008\", \"2007\", \"2006\", \"2005\"],\n",
    "    \"2000-early\": [\"2004\", \"2003\", \"2002\", \"2001\", \"2000\"],\n",
    "    \"1999-other\": [\"1999\", \"1970\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a775598",
   "metadata": {},
   "source": [
    "qualitycheck = {}\n",
    "for yeargroup in yearsetup:\n",
    "    for localyear in yearsetup[yeargroup]:\n",
    "        qualitycheck[localyear] = yeargroup\n",
    "for year in yearholder:\n",
    "    if year not in qualitycheck:\n",
    "        print(f\"!!!!!!! Missing {year}\")\n",
    "for year in sorted(qualitycheck):\n",
    "    print(f\"{year} ... {qualitycheck[year]}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b41e1e51",
   "metadata": {},
   "source": [
    "for yeargroup in yearsetup:\n",
    "    with open(f\"vice-index-{yeargroup}.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(list(masterlist[0].keys()))   # Write the header\n",
    "        for yearentry in yearsetup[yeargroup]:\n",
    "            for row in yearholder[yearentry]:\n",
    "                writer.writerow(list(row.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fec0f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hahaha, no, the late 2010s are twice the size of everything else combined.\n",
    "\n",
    "for year in yearholder:\n",
    "    with open(f\"vice-index-annual-{year}.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(list(masterlist[0].keys()))    # Writer the header\n",
    "        for row in yearholder[year]:\n",
    "            writer.writerow(list(row.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d774b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "authorindex = {}\n",
    "for year in yearholder:\n",
    "    for row in yearholder[year]:\n",
    "        for author in row['authors'].split(\"|\"):\n",
    "            if author not in authorindex:\n",
    "                authorindex[author] = {}\n",
    "            if year not in authorindex[author]:\n",
    "                authorindex[author][year] = 0\n",
    "            authorindex[author][year] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "646760df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"author-index.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow([\"author\", \"year\", \"storycount\"])\n",
    "    for author in sorted(authorindex):\n",
    "        for year in sorted(authorindex[author]):\n",
    "            storycount = authorindex[author][year]\n",
    "            writer.writerow([author, year, storycount])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447c83b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
